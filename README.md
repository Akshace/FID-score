# FID-score
The Fr√©chet inception distance (FID) is a metric used to assess the quality of images created by a generative model, like a generative adversarial network (GAN). The FID compares the distribution of generated images with the distribution of real images that were used to train the generator.

The FID metric is the squared Wasserstein metric between two multidimensional Gaussian distributions: {\displaystyle {\mathcal {N}}(\mu ,\Sigma )}{\displaystyle {\mathcal {N}}(\mu ,\Sigma )}, the distribution of some neural network features of the images generated by the GAN and {\displaystyle {\mathcal {N}}(\mu _{w},\Sigma _{w})}{\displaystyle {\mathcal {N}}(\mu _{w},\Sigma _{w})} and the distribution of the same neural network features from the "world" or real images used to train the GAN. As a neural network the Inception v3 trained on the ImageNet is commonly used. As a result, it can be computed from the mean and the covariance of the activations when the synthesized and real images are fed into the Inception network as:

{\displaystyle {\text{FID}}=|\mu -\mu _{w}|^{2}+\operatorname {tr} (\Sigma +\Sigma _{w}-2(\Sigma \Sigma _{w})^{1/2}).}{\displaystyle {\text{FID}}=|\mu -\mu _{w}|^{2}+\operatorname {tr} (\Sigma +\Sigma _{w}-2(\Sigma \Sigma _{w})^{1/2}).}

Rather than directly comparing images pixel by pixel (for example, as done by the L2 norm), the FID compares the mean and standard deviation of one of the deeper layers in a convolutional neural network named Inception v3. These layers are closer to output nodes that correspond to real-world objects such as a specific breed of dog or an airplane, and further from the shallow layers near the input image. As a result, they tend to mimic human perception of similarity in images.

Calculation of FID-score from the generated images from pix2pixHD Model.


Run command :

python fid.py --path1 ./Real --path2 ./Fake --batch-size 1
